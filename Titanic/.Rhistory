library(boot)
set.seed(19)
samp=rnorm(15,0,1)
boot_mean=function(data){
mean(samp)
}
boot.mean=function(data){
mean(samp)
}
b1=boot(data=samp,statistic = boot.mean(), R=1000 )
b1=boot(data=samp,statistic = boot.mean, R=1000 )
library(boot)
set.seed(19)
samp=rnorm(15,0,1)
boot.mean=function(data){
mean(data)
}
b1=boot(data=samp,statistic = boot.mean, R=1000 )
b1=boot(data=samp,statistic = mean(), R=1000 )
b1=boot(data=samp,statistic = mean, R=1000 )
library(boot)
set.seed(19)
samp=rnorm(15,0,1)
boot.mean=function(data){
return(mean(data))
}
b1=boot(data=samp,statistic = boot.mean, R=1000 )
return(mean(data))
boot.mean=function(data){
return(mean(data))
}
b1=boot(data=samp,statistic = boot.mean, R=1000 )
b1=boot(data=samp,statistic = boot.mean(samp), R=1000 )
?boot
mean.fn=function(data){
return(mean(data))
}
b1=boot(data=samp,statistic = mean.fn, R=1000 )
samp=rnorm(15,0,1)
mean.fn=function(data){
return(mean(data))
}
b1=boot(data=samp,statistic = mean.fn, R=1000 )
samp=rnorm(15,0,1)
mean.fn=function(data,index){
return(mean(data[index]))
}
b1=boot(data=samp,statistic = mean.fn, R=1000 )
library(boot)
set.seed(19)
samp=rnorm(15,0,1)
mean.fn=function(data,index){
return(mean(data[index]))
}
b1=boot(data=samp,statistic = mean.fn, R=1000 )
View(b1)
boot(data=samp,statistic = mean.fn, R=1000 )
View(b1)
library(boot)
mean.fn=function(data,index){
return(mean(data[index]))
}
samp=rnorm(15,0,1)
b1=boot(data=samp,statistic = mean.fn, R=1000 )
b1=boot(data=samp,statistic = mean.fn, R=1000)
View(b1)
View(b1)
b1@t0
b1&t
b1@t1
b1@t-
0
b1@t0
b1$t0
b1
b1$t0
b1$t1
b1$R
mean.fn=function(data,index){
return(confint(data[index]))
}
samp=rnorm(15,0,1)
b1=boot(data=samp,statistic = mean.fn, R=1000)
return(mean(data[index]))
mean.fn=function(data,index){
return(mean(data[index]))
}
samp=rnorm(15,0,1)
b1=boot(data=samp,statistic = mean.fn, R=1000)
library(boot)
mean.fn=function(data,index){
return(mean(data[index]))
}
samp=rnorm(15,0,1)
b1=boot(data=samp,statistic = mean.fn, R=1000)
b1
?quantile
quantile(b1,probs=c(0.025,0.975))
quantile(b1$t,probs=c(0.025,0.975))
library(boot)
#mean function for bootstrapping
mean.fn=function(data,index){
return(mean(data[index]))
}
#create sample of n=15 with mean=0 and 1
samp=rnorm(15,0,1)
#bootstrap for mean
b1=boot(data=samp,statistic = mean.fn, R=1000)
#confint for bootstrap
quantile(b1$t,probs=c(0.025,0.975))
#confit of t-dsitribution
quantile(b1$t,probs=c(0.025,0.975),df=14)
#confit of t-dsitribution
quantile(b1$t,probs=c(0.025,0.975),df=14)
?quantile
#confit of t-dsitribution
quantile(b1$t,probs=c(0.025,0.975),df=14)
#create sample of n=15 with mean=0 and 1
samp=rnorm(15,0,1)
#bootstrap for mean
b1=boot(data=samp,statistic = mean.fn, R=1000)
#confint for bootstrap
quantile(b1$t,probs=c(0.025,0.975))
#confit of t-dsitribution
quantile(b1$t,probs=c(0.025,0.975),df=14)
#confit of t-dsitribution
quantile(probs=c(0.025,0.975), df=14)
#confit of t-dsitribution
quantile(c(0.025,0.975), df=14)
#confit of t-dsitribution
quantile(b1$t,probs=c(0.025,0.975), df=14)
#confit of t-dsitribution
quantile(samp,probs=c(0.025,0.975), df=14)
#confint for bootstrap
quantile(b1$t,probs=c(0.025,0.975))
#confit of t-dsitribution
quantile(samp,probs=c(0.025,0.975), df=14)
c=quantile(samp,probs=c(0.025,0.975), df=14)
#see if mean falls within bootstrap confint 95% of time for 1000 runs
counter=0
for(i in 1000){
samp=rnorm(15,0,1)
b1=boot(data=samp,statistic = mean.fn, R=1000)
qt=quantile(b1$t,probs=c(0.025,0.975))
if (qt[1]<0 & qt[2]>0) {
counter=counter+1
}
}
perenctage_mean=counter/1000
#see if mean falls within bootstrap confint 95% of time for 1000 runs
counter=0
for(i in 10000){
samp=rnorm(15,0,1)
b1=boot(data=samp,statistic = mean.fn, R=1000)
qt=quantile(b1$t,probs=c(0.025,0.975))
if (qt[1]<0 & qt[2]>0) {
counter=counter+1
}
}
for(i in 10000){
samp=rnorm(15,0,1)
b1=boot(data=samp,statistic = mean.fn, R=1000)
qt=quantile(b1$t,probs=c(0.025,0.975))
if (qt[1]<0 & qt[2]>0) {
counter=counter+1
}
}
perenctage_mean=counter/1000
#see if mean falls within bootstrap confint 95% of time for 1000 runs
counter=0
for(i in 10000){
samp=rnorm(15,0,1)
b1=boot(data=samp,statistic = mean.fn, R=1000)
qt=quantile(b1$t,probs=c(0.025,0.975))
if (qt[1]<0 & qt[2]>0) {
counter=counter+1
}
}
######## FROM HERE TO THE NEXT SET OF #######
######## (BELOW) RUN THE CODE ALL AT ONCE (NOT LINE BY LINE)
install.packages("dplyr")
library(dplyr)
library(dplyr)
library(dplyr) # For data manipulation
# Fetch car miles-per-gallon data from the UCI Machine Learning Repository
url <-"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"
mpg <- read.table(url, stringsAsFactors = FALSE, na.strings="?", header=FALSE)
names(mpg) <- c("mpg","cyl","disp","hp","weight","accel","year","origin","name")
head(mpg)
# Look at the data and reset some of the data types
dim(mpg); summary(mpg)
str(mpg)
?sapply
# Look at the data and reset some of the data types
dim(mpg); summary(mpg)
sapply(mpg,class)
mpg <- mutate(mpg, hp = as.numeric(hp),
year = as.numeric(year),
origin = as.factor(origin))
head(mpg,2)
# Check to see if any observations have NAs
sum(is.na(mpg))
which(is.na(mpg == TRUE))
# Omit observations with NAs
mpg <- na.omit(mpg)
#
# Function to divide data into training, and test sets
index <- function(data=data,pctTrain=0.7)
{
# fcn to create indices to divide data into random
# training, validation/testing data sets
N <- nrow(data)
train <- sample(N, pctTrain*N)
test <- setdiff(seq_len(N),train)
Ind <- list(train=train,test=test)
return(Ind)
}
#
set.seed(123)
ind <- index(mpg, 0.8)
length(ind$train); length(ind$test)
str(mpg)
mpg[8,9]
mpg[,(8,9)]
mpg[,c(8,9)]
### YOUR GOAL IS TO DEVISE A CLASSIFIER THAT PREDICTS WHETHER OR NOT A CAR
### IS MANUFACTURED IN THE USA. HOW DO YOU DO IT?
mpg$origin=ifelse(mpg$origin==1, 1,2)
form <- formula("origin ~ cyl + disp + hp + weight + accel + year + mpg")
rf_fit <- tree(formula=form,data=na.omit(mpg[ind$train,])) # Build the model (use rpart if you wish)
library(tree)
rf_fit <- tree(formula=form,data=na.omit(mpg[ind$train,])) # Build the model (use rpart if you wish)
form <- formula("origin ~ cyl + disp + hp + weight + accel + year + mpg")
f
### Use the methodology described in section 8.3 of your textbook to utilize your CART model (above) to:
### (A) Produce a CART plot, with text, and calculate the training set error rate
plot(rf_fit)
text(rf_fit, pretty=0)
trainerror=predict(rf_fit,newdata = TRUE)
trainerror=predict(rf_fit,newdata = mpg[ind$train])
trainerror=predict(rf_fit)
trainerror=ifelse(predict(rf_fit)<=1.5, 1,2)
table(trainerror,mpg$train)
table(trainerror,mpg[train,]$origin)
train <- sample(N, pctTrain*N)
table(trainerror,mpg[train,]$origin)
table(trainerror, na.omit(mpg[ind$train,])$origin)
### (B) Calculate the test set error rate
testerror=ifelse(predict(rf_fit,newdata = mpg[ind$test,])<=1.5, 1,2)
table(testerror, na.omit(mpg[ind$test,])$origin)
### (C) Consider whether pruning the tree might improve accuracy; identify optimal 'alpha'
cv.tree(rf_fit, FUN=prune.missclass)
### (C) Consider whether pruning the tree might improve accuracy; identify optimal 'alpha'
cv=cv.tree(rf_fit, FUN=prune.missclass)
cv
### (C) Consider whether pruning the tree might improve accuracy; identify optimal 'alpha'
cv=cv.tree(rf_fit, FUN=prune.missclass)
### (C) Consider whether pruning the tree might improve accuracy; identify optimal 'alpha'
cv=cv.tree(rf_fit, FUN=misclass.tree())
### (C) Consider whether pruning the tree might improve accuracy; identify optimal 'alpha'
cv=cv.tree(rf_fit, FUN=misclass.tree())
### (C) Consider whether pruning the tree might improve accuracy; identify optimal 'alpha'
cv=cv.tree(rf_fit, FUN=prune.misclass())
### (C) Consider whether pruning the tree might improve accuracy; identify optimal 'alpha'
cv=cv.tree(rf_fit, FUN=prune.misclass)
### YOUR GOAL IS TO DEVISE A CLASSIFIER THAT PREDICTS WHETHER OR NOT A CAR
### IS MANUFACTURED IN THE USA. HOW DO YOU DO IT?
mpg$origin=ifelse(mpg$origin==1, TRUE,FALSE)
form <- formula("origin ~ cyl + disp + hp + weight + accel + year + mpg")
rf_fit <- tree(formula=form,data=na.omit(mpg[ind$train,])) # Build the model (use rpart if you wish)
### Use the methodology described in section 8.3 of your textbook to utilize your CART model (above) to:
### (A) Produce a CART plot, with text, and calculate the training set error rate
plot(rf_fit)
text(rf_fit, pretty=0)
trainerror=ifelse(predict(rf_fit)<=1.5, 1,2)
table(trainerror, na.omit(mpg[ind$train,])$origin)
### (B) Calculate the test set error rate
testerror=ifelse(predict(rf_fit,newdata = mpg[ind$test,])<=1.5, 1,2)
table(testerror, na.omit(mpg[ind$test,])$origin)
### (C) Consider whether pruning the tree might improve accuracy; identify optimal 'alpha'
cv=cv.tree(rf_fit, FUN=prune.misclass)
### YOUR GOAL IS TO DEVISE A CLASSIFIER THAT PREDICTS WHETHER OR NOT A CAR
### IS MANUFACTURED IN THE USA. HOW DO YOU DO IT?
mpg$origin=as.factor(ifelse(mpg$origin==1, 1,2))
form <- formula("origin ~ cyl + disp + hp + weight + accel + year + mpg")
trainerror=ifelse(predict(rf_fit)<=1.5, 1,2, type=class())
table(trainerror, na.omit(mpg[ind$train,])$origin)
### YOUR GOAL IS TO DEVISE A CLASSIFIER THAT PREDICTS WHETHER OR NOT A CAR
### IS MANUFACTURED IN THE USA. HOW DO YOU DO IT?
mpg$origin=ifelse(mpg$origin==1, 1,2)
form <- formula("origin ~ cyl + disp + hp + weight + accel + year + mpg")
rf_fit <- tree(formula=form,data=na.omit(mpg[ind$train,])) # Build the model (use rpart if you wish)
### Use the methodology described in section 8.3 of your textbook to utilize your CART model (above) to:
### (A) Produce a CART plot, with text, and calculate the training set error rate
plot(rf_fit)
text(rf_fit, pretty=0)
trainerror=ifelse(predict(rf_fit)<=1.5, 1,2, type=class())
table(trainerror, na.omit(mpg[ind$train,])$origin)
rf_fit <- tree(formula=form,data=na.omit(mpg[ind$train,]), method = class) # Build the model (use rpart if you wish)
### Use the methodology described in section 8.3 of your textbook to utilize your CART model (above) to:
### (A) Produce a CART plot, with text, and calculate the training set error rate
plot(rf_fit)
text(rf_fit, pretty=0)
trainerror=ifelse(predict(rf_fit)<=1.5, 1,2, type=class())
table(trainerror, na.omit(mpg[ind$train,])$origin)
### (B) Calculate the test set error rate
testerror=ifelse(predict(rf_fit,newdata = mpg[ind$test,])<=1.5, 1,2)
table(testerror, na.omit(mpg[ind$test,])$origin)
### (C) Consider whether pruning the tree might improve accuracy; identify optimal 'alpha'
cv=cv.tree(rf_fit, FUN=prune.misclass)
#part1
setwd("~/Minerva Year 2/CS112/R-datasets/Titanic")
train <- read.csv("~/Minerva Year 2/CS112/R-datasets/Titanic/all/train.csv")
test <- read.csv("~/Minerva Year 2/CS112/R-datasets/Titanic/all/test.csv")
str(train)
a=table(train$Survived)
prop.table(a)
test$Survived <- rep(0,418)
submit <- data.frame(PassengerId=test$PassengerId, Survived =test$survived)
write.csv(submit, file="theyallperish.csv", row.names = FALSE)
#part2
summary(train$Sex)
prop.table()
test$Survived[test$Sex=="female"] <- 1
train$Child <- 0
train$Child[train$Age<18] <- 1
aggregate(Survived ~ Child+Sex, data=train, FUN=sum)
aggregate(Survived ~ Child+Sex, data=train, FUN=function(x) {sum(x)/length(x)})
train$Fare2 <- "30+"
train$Fare2[train$Fare<30 & train$Fare >=20] <-"20-30"
train$Fare2[train$Fare<20 & train$Fare >=10] <-"10-20"
train$Fare2[train$Fare<10] <-"<10"
aggregate(Survived ~Fare2 +Pclass + Sex, data = train, FUN=function(x) {sum(x)/length(x)})
test$Survived <- 0
test$Survived[test$Sex=="female"] <- 1
test$Survived[test$Sex=="female" & test$Pclass ==3 & test$Fare>=20] <- 0
#part 3
library(rpart)
fit <-rpart(Survived ~ Pclass+Sex+Age+SibSp+Parch+Fare+Embarked,data = train, method ="class")
plot(fit)
text(fit)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(fit)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(fit)
fancyRpartPlot(fit)
< write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
?rpart
?rpart.control
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=train,
method="class",
control=rpart.control(minsplit=2, cp=0))
View(fit)
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=train,
method="class",
control=rpart.control(minsplit=2, cp=0))
fancyRpartPlot(fit)
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=train,
method="class",
control=rpart.control(minsplit=6, cp=0))
fancyRpartPlot(fit)
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=train,
method="class",
control=rpart.control(minsplit=8, cp=0))
fancyRpartPlot(fit)
?rpart.control
#part 4
test$Survived <- NA
combi <rbind(train,test)
combi <- rbind(train,test)
#part4
setwd("~/Minerva Year 2/CS112/R-datasets/Titanic")
train <- read.csv("~/Minerva Year 2/CS112/R-datasets/Titanic/all/train.csv")
test <- read.csv("~/Minerva Year 2/CS112/R-datasets/Titanic/all/test.csv")
test$Survived <- NA
combi <- rbind(train, test)
combi$Name <- as.character(combi$Name)
combi$name[1]
combi$Name[1]
strsplit(combi$Name[1],split = "[,.]")
strsplit(combi$Name[1],split = "[,.]")[[1]]
strsplit(combi$Name[1],split = "[,.]")[[1]][2]
combi$Title <- sapply(combi$Name, FUN=function(x)strsplit(x[1],split = "[,.]")[[1]][2])
combi$Title <- sub(' ', '', combi$Title)
table(combi$Title)
> combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
combi$Title <- factor(combi$Title)
combi$FamilySize <- combi$SibSp + combi$Parch + 1
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
table(combi$FamilyID)
famIDs <- data.frame(table(combi$FamilyID))
View(famIDs)
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
combi$FamilyID <- factor(combi$FamilyID)
train <- combi[1:891,]
test <- combi[892:1309,]
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data=train,
method="class")
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize,
data=combi[!is.na(combi$Age),],
method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
combi$Fare[1044] <- median(combi$Fare, na.rm=TRUE)
combi$Embarked[c(62,830)] = "S"
combi$Embarked <- factor(combi$Embarked)
combi$FamilyID2 <- combi$FamilyID
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'
combi$FamilyID2 <- factor(combi$FamilyID2)
combi$FamilyID2
install.packages("randomForest")
library(randomForest)
set.seed(19)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare +
Embarked + Title + FamilySize + FamilyID2,
data=train,
importance=TRUE,
ntree=2000)
combi$FamilyID2 <- combi$FamilyID
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'
combi$FamilyID2 <- factor(combi$FamilyID2)
library(randomForest)
set.seed(19)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare +
Embarked + Title + FamilySize + FamilyID2,
data=train,
importance=TRUE,
ntree=2000)
View(train)
train$FamilyID2= combi$FamilyID2[train]
train$FamilyID2= combi$FamilyID2[train$FamilyID]
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare +
Embarked + Title + FamilySize + FamilyID2,
data=train,
importance=TRUE,
ntree=2000)
#part4
setwd("~/Minerva Year 2/CS112/R-datasets/Titanic")
train <- read.csv("~/Minerva Year 2/CS112/R-datasets/Titanic/all/train.csv")
test <- read.csv("~/Minerva Year 2/CS112/R-datasets/Titanic/all/test.csv")
test$Survived <- NA
combi <- rbind(train, test)
combi$Name <- as.character(combi$Name)
combi$Name[1]
strsplit(combi$Name[1],split = "[,.]")[[1]][2]
combi$Title <- sapply(combi$Name, FUN=function(x)strsplit(x[1],split = "[,.]")[[1]][2])
combi$Title <- sub(' ', '', combi$Title)
table(combi$Title)
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
combi$Title <- factor(combi$Title)
combi$FamilySize <- combi$SibSp + combi$Parch + 1
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
table(combi$FamilyID)
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
combi$FamilyID <- factor(combi$FamilyID)
train <- combi[1:891,]
test <- combi[892:1309,]
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data=train,
method="class")
#part 5
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize,
data=combi[!is.na(combi$Age),],
method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
combi$Fare[1044] <- median(combi$Fare, na.rm=TRUE)
combi$Embarked[c(62,830)] = "S"
combi$Embarked <- factor(combi$Embarked)
combi$FamilyID2 <- combi$FamilyID
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'
combi$FamilyID2 <- factor(combi$FamilyID2)
library(randomForest)
set.seed(19)
#train$FamilyID2= combi$FamilyID2[train$FamilyID]
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare +
Embarked + Title + FamilySize + FamilyID,
data=train,
importance=TRUE,
ntree=2000)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare +
Embarked + Title + FamilySize + FamilyID,
data=train,
importance=TRUE,
ntree=2000)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare +
Embarked + Title + FamilySize + FamilyID,
data=combi,
importance=TRUE,
ntree=2000)
